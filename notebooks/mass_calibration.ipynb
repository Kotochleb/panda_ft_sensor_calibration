{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pinocchio as pin\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "# Set numpy precision to show easier to understand values\n",
    "np.set_printoptions(formatter={\"float_kind\": \"{:.3f}\".format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joint_states = pd.read_parquet(\"data/jtc/franka_joint_states_measurements.parquet\")\n",
    "df_ft = pd.read_parquet(\n",
    "    \"data/jtc/force_torque_sensor_broadcaster_wrench_measurements.parquet\"\n",
    ")\n",
    "df_moving_to_pose = pd.read_parquet(\"data/jtc/moving_to_new_pose_measurements.parquet\")\n",
    "df_pose_reached = pd.read_parquet(\"data/jtc/pose_reached_measurements.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract timestamps of stationary poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dummy variables to easier detect state transitions after concatenations\n",
    "df_pose_reached[\"state\"] = 0\n",
    "df_moving_to_pose[\"state\"] = 1\n",
    "# Filter moving to pose topics that are after a first pose was reached\n",
    "df_moving_to_pose = df_moving_to_pose.loc[\n",
    "    (df_moving_to_pose[\"timestamp\"] - df_pose_reached[\"timestamp\"][0]) > 0\n",
    "]\n",
    "# Concatenate both dataframes and sort new dataframe by timestamp\n",
    "df_stamps = pd.concat((df_moving_to_pose, df_pose_reached)).sort_values(\n",
    "    by=[\"timestamp\"], ignore_index=True\n",
    ")\n",
    "# Filter timestamps where robot stays in place. This means difference between next state and current state is -1\n",
    "# And time difference between messages appearing has to be larder than 19 second (robot was suppose to wait 20 seconds)\n",
    "df_stamps_stationary = df_stamps[\n",
    "    (df_stamps[\"state\"].diff() == -1.0) & (-df_stamps[\"timestamp\"].diff(-1) > 19 * 1e9)\n",
    "]\n",
    "df_stamps_stationary.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create more accurate timestamps based on header messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joint_states[\"header.stamp\"] = (\n",
    "    df_joint_states[\"header.stamp.sec\"] * 1e9 + df_joint_states[\"header.stamp.nanosec\"]\n",
    ")\n",
    "df_ft[\"header.stamp\"] = df_ft[\"header.stamp.sec\"] * 1e9 + df_ft[\"header.stamp.nanosec\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract parts of the dataframes that correspond only to the measured poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map dataframes to topic names\n",
    "measurements = {\n",
    "    \"joint_states\": df_joint_states,\n",
    "    \"force_torque\": df_ft,\n",
    "}\n",
    "\n",
    "stationary_data = {}\n",
    "# Choose offsets for clipping\n",
    "start_stamp_offset = int(3.0 * 1e9)  # 3 seconds\n",
    "end_stamp_offset = int(19.0 * 1e9)  # 19 seconds\n",
    "for i, data in df_stamps_stationary.iterrows():\n",
    "    # Compute start and end time\n",
    "    start = data[\"timestamp\"] + start_stamp_offset\n",
    "    end = data[\"timestamp\"] + end_stamp_offset\n",
    "    pose_name = data[\"data\"]\n",
    "    if pose_name not in stationary_data.keys():\n",
    "        stationary_data[pose_name] = []\n",
    "    stationary_data[pose_name].append(\n",
    "        {\n",
    "            topic: df.loc[(df[\"header.stamp\"] > start) & (df[\"header.stamp\"] < end)]\n",
    "            for topic, df in measurements.items()\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load URDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full = pin.buildModelFromUrdf(\"data/fer.urdf\")\n",
    "joints_to_lock = [\n",
    "    model_full.getJointId(name) for name in model_full.names if \"finger\" in name\n",
    "]\n",
    "model = pin.buildReducedModel(model_full, joints_to_lock, np.zeros(model_full.nq))\n",
    "\n",
    "data = model.createData()\n",
    "\n",
    "joint_order = [name for name in model.names if name != \"universe\"]\n",
    "base_frame_id = model.getFrameId(\"fer_link0\")\n",
    "tcp_pose_frame_id = model.getFrameId(\"fer_link8\")\n",
    "sensor_frame_id = model.getFrameId(\"ati_mini45_measurement_reference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remap joint order\n",
    "Joint state publisher does not guarantee to be publish joints in the same order all the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that will not be used\n",
    "columns_to_drop = [\n",
    "    \"timestamp\",\n",
    "    \"header.stamp.sec\",\n",
    "    \"header.stamp.nanosec\",\n",
    "    \"header.frame_id\",\n",
    "]\n",
    "\n",
    "\n",
    "def reorder_joints(row):\n",
    "    joints = row[\"name\"]\n",
    "    joint_map = [np.argwhere(joints == joint_name)[0][0] for joint_name in joint_order]\n",
    "    row[\"name\"] = joint_order\n",
    "    row[\"position\"] = row[\"position\"][joint_map]\n",
    "    row[\"velocity\"] = row[\"velocity\"][joint_map]\n",
    "    row[\"effort\"] = row[\"effort\"][joint_map]\n",
    "    return row\n",
    "\n",
    "\n",
    "for pose in stationary_data.keys():\n",
    "    for i in range(len(stationary_data[pose])):\n",
    "        df1 = stationary_data[pose][i][\"force_torque\"].drop(columns=columns_to_drop)\n",
    "        df2 = stationary_data[pose][i][\"joint_states\"].drop(columns=columns_to_drop)\n",
    "        df_merged = pd.merge(df1, df2, on=[\"header.stamp\"]).dropna()\n",
    "        stationary_data[pose][i][\"merged\"] = df_merged.apply(reorder_joints, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute average values for each configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_710/1516012944.py:8: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  stationary_data[pose][i][\"merged\"].drop(columns=[\"name\", \"position\"]).mean()\n"
     ]
    }
   ],
   "source": [
    "averaged_stationary_data = {}\n",
    "\n",
    "for pose in stationary_data.keys():\n",
    "    averaged_stationary_data[pose] = []\n",
    "    for i in range(len(stationary_data[pose])):\n",
    "        position = stationary_data[pose][i][\"merged\"][\"position\"]\n",
    "        averaged_stationary_data[pose].append(\n",
    "            stationary_data[pose][i][\"merged\"].drop(columns=[\"name\", \"position\"]).mean()\n",
    "        )\n",
    "        # Position has to be computed separately as it is not a scalar\n",
    "        averaged_stationary_data[pose][i][\"position\"] = position.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute rotation matrices and force and torque vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_stationary_data = {}\n",
    "\n",
    "for pose in averaged_stationary_data.keys():\n",
    "    processed_stationary_data[pose] = []\n",
    "    for i in range(len(averaged_stationary_data[pose])):\n",
    "        data_sample = averaged_stationary_data[pose][i]\n",
    "        pin.framesForwardKinematics(model, data, data_sample[\"position\"])\n",
    "\n",
    "        R_wm = data.oMf[base_frame_id].actInv(data.oMf[tcp_pose_frame_id]).rotation\n",
    "        R_ws = data.oMf[base_frame_id].actInv(data.oMf[sensor_frame_id]).rotation\n",
    "        processed_stationary_data[pose].append(\n",
    "            {\n",
    "                # Rotation from world to mounting plate\n",
    "                \"R_wm\": np.array(R_wm, copy=True),\n",
    "                # Rotation from world to sensor frame\n",
    "                \"R_ws\": np.array(R_ws, copy=True),\n",
    "                # Negate both force and torque as measurements are flipped\n",
    "                \"f\": -np.array([data_sample[\"wrench.force.\" + dir] for dir in \"xyz\"]),\n",
    "                \"tau\": -np.array(\n",
    "                    [data_sample[\"wrench.torque.\" + dir] for dir in \"xyz\"]\n",
    "                ),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate rotations\n",
    "\n",
    "Ensure rotation matrices computed from averaged joint configurations match valued expected during the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose name       delta angle in degrees\n",
      "\n",
      "down_1          [-0.156 0.091 0.145]\n",
      "down_0          [-0.150 0.025 0.182]\n",
      "down_2          [-0.121 -0.004 0.006]\n",
      "up_side_down_1  [-0.215 -0.506 0.545]\n",
      "up_side_down_2  [-0.249 -0.509 0.120]\n",
      "up_side_down_0  [-0.139 -0.387 0.253]\n",
      "curled_1        [0.192 0.447 0.033]\n",
      "curled_0        [0.067 0.402 -0.002]\n",
      "curled_2        [0.061 0.340 -0.002]\n",
      "up_right_0      [0.028 -0.119 0.302]\n",
      "up_right_1      [0.028 -0.024 0.303]\n",
      "up_right_2      [0.028 -0.077 0.303]\n",
      "up_right_3      [0.024 -0.122 0.301]\n",
      "stretched_0     [-0.003 0.697 -0.426]\n",
      "stretched_1     [0.187 0.586 -0.318]\n",
      "stretched_2     [0.261 0.484 -0.240]\n",
      "stretched_3     [0.175 0.419 -0.266]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../config/reference_pose_publisher_params.yaml\") as stream:\n",
    "    try:\n",
    "        params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "params = params[\"/**\"][\"ros__parameters\"]\n",
    "keys = [key for key in set(params[\"poses_to_reach_names\"]) if \"_transition\" not in key]\n",
    "expected_configurations = {\n",
    "    key: pin.Quaternion(np.array(params[key][\"quat\"])) for key in keys\n",
    "}\n",
    "\n",
    "print(f\"{'pose name':15} delta angle in degrees\")\n",
    "print()\n",
    "for p in processed_stationary_data.keys():\n",
    "    pose = processed_stationary_data[p][0]\n",
    "    expected_quat = expected_configurations[p]\n",
    "\n",
    "    diff = expected_quat * pin.Quaternion(pose[\"R_wm\"].T)\n",
    "    print(f\"{p:15}\", np.rad2deg(pin.rpy.matrixToRpy(diff.matrix())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model only on forces\n",
    "\n",
    "This checks if a simpler model can be fit. Initial mass is larger than what can be found in URDF of the robot. Rotation is between expected frame, based on the datasheet making the whole method do only small refinement, smaller than 5 degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0.7841372455659875 [kg]\n",
      "v: [-1.072 -0.012 0.313] [deg]\n",
      "b: [-1.597 5.188 4.400] [N]\n"
     ]
    }
   ],
   "source": [
    "# Create gravity vector\n",
    "g = np.array([0.0, 0.0, -9.81])\n",
    "\n",
    "# Initial guess for bias based on two poses, where expected measured force can be guesses\n",
    "b_init = (\n",
    "    processed_stationary_data[\"down_0\"][0][\"f\"]\n",
    "    + processed_stationary_data[\"up_side_down_0\"][0][\"f\"]\n",
    ") / 2\n",
    "# Bound expected bias\n",
    "b_lim = [sorted((0.5 * b, 1.5 * b)) for b in b_init]\n",
    "\n",
    "\n",
    "# Cost function\n",
    "def cost(x):\n",
    "    # Mass\n",
    "    m = x[0]\n",
    "    # Angular velocity between expected sensor frame and refined sensor frame\n",
    "    v = x[1:4]\n",
    "    # Bias\n",
    "    b = x[4:]\n",
    "    sum = 0.0\n",
    "    j = 0.0\n",
    "    for p in processed_stationary_data.keys():\n",
    "        for i in range(len(processed_stationary_data[p])):\n",
    "            pose = processed_stationary_data[p][i]\n",
    "            R = pose[\"R_ws\"].copy()\n",
    "            f = pose[\"f\"].copy()\n",
    "\n",
    "            sum += np.linalg.norm(m * pin.exp3(v).T @ R.T @ g - (f - b))\n",
    "            j += 1.0\n",
    "    # Return normalized cost\n",
    "    return sum / j\n",
    "\n",
    "\n",
    "rot_err = np.deg2rad(5)\n",
    "\n",
    "# SLSQP is used without gradient.\n",
    "# This way it approximates it.\n",
    "res = scipy.optimize.minimize(\n",
    "    cost,\n",
    "    [0.8, 0.0, 0.0, 0.0, *b_init],\n",
    "    method=\"SLSQP\",\n",
    "    bounds=[\n",
    "        (0.78, 1.0),\n",
    "        (-rot_err, rot_err),\n",
    "        (-rot_err, rot_err),\n",
    "        (-rot_err, rot_err),\n",
    "        *b_lim,\n",
    "    ],\n",
    "    tol=1e-7,\n",
    ")\n",
    "m = res.x[0]\n",
    "v = res.x[1:4]\n",
    "b = res.x[4:]\n",
    "print(f\"m: {m} [kg]\")\n",
    "print(f\"v: {np.rad2deg(pin.rpy.matrixToRpy(pin.exp3(v)))} [deg]\")\n",
    "print(f\"b: {b} [N]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results\n",
    "\n",
    "Convert unbiased, measured force to world frame. Expected values is, all vectors are close to gravity vector and cost being close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose name       Normalized measured force in world frame   cost\n",
      "\n",
      "down_1          [0.042 -0.368 -9.372]                      0.592\n",
      "down_0          [0.348 -0.278 -9.428]                      0.693\n",
      "down_2          [0.230 -0.028 -9.454]                      0.523\n",
      "up_side_down_1  [-0.240 -0.097 -10.785]                    0.805\n",
      "up_side_down_2  [0.086 -0.458 -10.724]                     0.773\n",
      "up_side_down_0  [0.086 -0.120 -10.724]                     0.802\n",
      "curled_1        [0.771 -0.351 -9.520]                      0.552\n",
      "curled_0        [0.546 -0.113 -9.928]                      0.608\n",
      "curled_2        [0.601 -0.114 -9.724]                      0.742\n",
      "up_right_0      [-0.171 0.339 -9.804]                      0.128\n",
      "up_right_1      [0.191 0.229 -9.582]                       0.297\n",
      "up_right_2      [-0.062 -0.008 -9.864]                     0.151\n",
      "up_right_3      [0.054 0.006 -9.750]                       0.285\n",
      "stretched_0     [-0.193 -0.327 -9.689]                     0.190\n",
      "stretched_1     [-0.102 0.025 -9.606]                      0.250\n",
      "stretched_2     [0.152 -0.184 -9.850]                      0.075\n",
      "stretched_3     [0.118 -0.024 -9.667]                      0.199\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'pose name':15} {'Normalized measured force in world frame':42} cost\")\n",
    "print()\n",
    "for p in processed_stationary_data.keys():\n",
    "    pose = processed_stationary_data[p][0]\n",
    "    R = pose[\"R_ws\"].copy()\n",
    "    f = pose[\"f\"].copy()\n",
    "    cost = np.linalg.norm(m * pin.exp3(v) @ R.T @ g - (f - b))\n",
    "    g_reconstruct = R @ pin.exp3(v) @ (f - b) / m\n",
    "    print(f\"{p:15} {str(g_reconstruct):42} {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model with forces and torques\n",
    "\n",
    "Extend the model to expect both forces and torques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0.7841395267896559 [kg]\n",
      "vr: [-1.072 -0.012 0.313] [deg]\n",
      "vm: [0.003 0.006 -0.050] [m]\n",
      "b: [-1.597 5.188 4.400 0.309 0.076 0.029] [N, N/m]\n"
     ]
    }
   ],
   "source": [
    "# Create gravity vector\n",
    "g = np.array([0.0, 0.0, -9.81])\n",
    "\n",
    "# Initial guess with force and torque\n",
    "b_init = (\n",
    "    np.hstack([processed_stationary_data[\"down_0\"][0][val] for val in (\"f\", \"tau\")])\n",
    "    + np.hstack(\n",
    "        [processed_stationary_data[\"up_side_down_0\"][0][val] for val in (\"f\", \"tau\")]\n",
    "    )\n",
    ") / 2\n",
    "# Create bounds for the initial guess\n",
    "b_lim = [sorted((0.5 * b, 1.5 * b)) for b in b_init]\n",
    "\n",
    "\n",
    "def cost(x):\n",
    "    # Mass\n",
    "    m = x[0]\n",
    "    # Angular velocity\n",
    "    vr = np.array(x[1:4])\n",
    "    # Angular velocity between expected sensor frame and refined sensor frame\n",
    "    vm = np.array(x[4:7])\n",
    "    # Bias\n",
    "    b = np.array(x[7:])\n",
    "    sum = 0.0\n",
    "    j = 0.0\n",
    "    for p in processed_stationary_data.keys():\n",
    "        for i in range(len(processed_stationary_data[p])):\n",
    "            pose = processed_stationary_data[p][i]\n",
    "            R = pose[\"R_ws\"].copy()\n",
    "            f = pose[\"f\"].copy()\n",
    "            tau = pose[\"tau\"].copy()\n",
    "\n",
    "            sum += np.linalg.norm(\n",
    "                np.vstack((np.eye(3), pin.skew(vm))) @ (m * pin.exp3(vr).T @ R.T @ g)\n",
    "                - (np.hstack((f, tau)) - b)\n",
    "            )\n",
    "            j += 1.0\n",
    "    # Return normalized cost\n",
    "    return sum / j\n",
    "\n",
    "\n",
    "rot_err = np.deg2rad(5)\n",
    "\n",
    "res = scipy.optimize.minimize(\n",
    "    cost,\n",
    "    [0.8, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, *b_init],\n",
    "    method=\"SLSQP\",\n",
    "    bounds=[\n",
    "        (0.78, 1.0),\n",
    "        (-rot_err, rot_err),\n",
    "        (-rot_err, rot_err),\n",
    "        (-rot_err, rot_err),\n",
    "        (-0.05, 0.05),\n",
    "        (-0.05, 0.05),\n",
    "        (-0.2, 0.2),\n",
    "        *b_lim,\n",
    "    ],\n",
    "    tol=1e-7,\n",
    ")\n",
    "m = res.x[0]\n",
    "vr = np.array(res.x[1:4])\n",
    "vm = np.array(res.x[4:7])\n",
    "b = np.array(res.x[7:])\n",
    "\n",
    "print(f\"m: {m} [kg]\")\n",
    "print(f\"vr: {np.rad2deg(pin.rpy.matrixToRpy(pin.exp3(v)))} [deg]\")\n",
    "print(f\"vm: {vm} [m]\")\n",
    "print(f\"b: {b} [N, N/m]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results\n",
    "\n",
    "Check if torques with bias removed can be recreated from measured forces without the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose name       Measured torque        Computed torque       \n",
      "\n",
      "down_1          [-0.047 0.030 0.000]   [-0.032 0.039 0.003]  \n",
      "down_1          [-0.048 0.039 0.001]   [-0.045 0.036 0.001]  \n",
      "down_0          [-0.035 0.022 0.001]   [-0.022 0.031 0.002]  \n",
      "down_0          [-0.034 0.033 -0.001]  [-0.033 0.031 0.002]  \n",
      "down_2          [-0.045 0.012 -0.004]  [-0.033 0.020 0.000]  \n",
      "down_2          [-0.041 0.021 -0.007]  [-0.040 0.019 -0.000] \n",
      "up_side_down_1  [0.039 -0.041 -0.001]  [0.047 -0.037 -0.001] \n",
      "up_side_down_1  [0.040 -0.040 0.004]   [0.036 -0.040 -0.003] \n",
      "up_side_down_2  [0.054 -0.024 -0.006]  [0.061 -0.016 0.002]  \n",
      "up_side_down_2  [0.054 -0.025 0.003]   [0.045 -0.023 0.000]  \n",
      "up_side_down_0  [0.038 -0.025 0.001]   [0.043 -0.021 0.000]  \n",
      "up_side_down_0  [0.040 -0.027 0.005]   [0.032 -0.028 -0.001] \n",
      "curled_1        [-0.324 0.193 0.004]   [-0.311 0.196 0.003]  \n",
      "curled_1        [-0.322 0.195 -0.001]  [-0.321 0.196 0.002]  \n",
      "curled_0        [0.199 0.330 0.056]    [0.201 0.330 0.056]   \n",
      "curled_0        [0.198 0.330 0.054]    [0.188 0.327 0.054]   \n",
      "curled_2        [0.323 -0.198 -0.006]  [0.327 -0.196 -0.002] \n",
      "curled_2        [0.319 -0.198 -0.005]  [0.314 -0.200 -0.003] \n",
      "up_right_0      [-0.198 -0.340 -0.052] [-0.186 -0.333 -0.055]\n",
      "up_right_0      [-0.196 -0.330 -0.053] [-0.197 -0.331 -0.056]\n",
      "up_right_1      [-0.329 0.194 0.004]   [-0.317 0.194 0.002]  \n",
      "up_right_1      [-0.324 0.194 -0.002]  [-0.328 0.192 0.001]  \n",
      "up_right_2      [0.193 0.334 0.053]    [0.192 0.332 0.055]   \n",
      "up_right_2      [0.193 0.335 0.052]    [0.179 0.328 0.054]   \n",
      "up_right_3      [0.325 -0.194 -0.005]  [0.326 -0.194 -0.002] \n",
      "up_right_3      [0.325 -0.193 -0.005]  [0.314 -0.198 -0.003] \n",
      "stretched_0     [-0.187 -0.338 -0.051] [-0.178 -0.332 -0.054]\n",
      "stretched_0     [-0.187 -0.334 -0.049] [-0.195 -0.336 -0.056]\n",
      "stretched_1     [-0.329 0.188 -0.000]  [-0.321 0.190 0.001]  \n",
      "stretched_1     [-0.330 0.191 0.000]   [-0.338 0.186 -0.000] \n",
      "stretched_2     [0.191 0.336 0.052]    [0.189 0.333 0.055]   \n",
      "stretched_2     [0.190 0.339 0.051]    [0.174 0.330 0.054]   \n",
      "stretched_3     [0.326 -0.189 0.009]   [0.325 -0.190 -0.001] \n",
      "stretched_3     [0.322 -0.185 0.006]   [0.311 -0.196 -0.003] \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'pose name':15} {'Measured torque':22} {'Computed torque':22}\")\n",
    "print()\n",
    "for p in processed_stationary_data.keys():\n",
    "    for i in range(len(processed_stationary_data[p])):\n",
    "        pose = processed_stationary_data[p][i]\n",
    "        R = pose[\"R_ws\"].copy()\n",
    "        f = pose[\"f\"].copy()\n",
    "        tau = pose[\"tau\"].copy()\n",
    "\n",
    "        # print(p, tau - b[3:], np.cross(vm, f - b[:3]))\n",
    "        print(f\"{p:15} {str(tau - b[3:]):22} {str(np.cross(vm, f - b[:3])):22}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic calibration. TBD..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control = pd.read_parquet(\"results/control_measurements.parquet\")\n",
    "df_ft = pd.read_parquet(\n",
    "    \"results/force_torque_sensor_broadcaster_wrench_measurements.parquet\"\n",
    ")\n",
    "df_franka_joint_states = pd.read_parquet(\n",
    "    \"results/franka_joint_states_measurements.parquet\"\n",
    ")\n",
    "df_sensor = pd.read_parquet(\"results/sensor_measurements.parquet\")\n",
    "\n",
    "\n",
    "df_joint_states[\"header.stamp\"] = (\n",
    "    df_joint_states[\"header.stamp.sec\"] * 1e9 + df_joint_states[\"header.stamp.nanosec\"]\n",
    ")\n",
    "df_ft[\"header.stamp\"] = df_ft[\"header.stamp.sec\"] * 1e9 + df_ft[\"header.stamp.nanosec\"]\n",
    "\n",
    "# Map dataframes to topic names\n",
    "measurements = {\n",
    "    \"joint_states\": df_joint_states,\n",
    "    \"force_torque\": df_ft,\n",
    "}\n",
    "\n",
    "stationary_data = {}\n",
    "# Choose offsets for clipping\n",
    "start_stamp_offset = int(3.0 * 1e9)  # 3 seconds\n",
    "end_stamp_offset = int(19.0 * 1e9)  # 19 seconds\n",
    "for i, data in df_stamps_stationary.iterrows():\n",
    "    # Compute start and end time\n",
    "    start = data[\"timestamp\"] + start_stamp_offset\n",
    "    end = data[\"timestamp\"] + end_stamp_offset\n",
    "    pose_name = data[\"data\"]\n",
    "    if pose_name not in stationary_data.keys():\n",
    "        stationary_data[pose_name] = []\n",
    "    stationary_data[pose_name].append(\n",
    "        {\n",
    "            topic: df.loc[(df[\"header.stamp\"] > start) & (df[\"header.stamp\"] < end)]\n",
    "            for topic, df in measurements.items()\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Remove columns that will not be used\n",
    "columns_to_drop = [\n",
    "    \"timestamp\",\n",
    "    \"header.stamp.sec\",\n",
    "    \"header.stamp.nanosec\",\n",
    "    \"header.frame_id\",\n",
    "]\n",
    "\n",
    "\n",
    "def reorder_joints(row):\n",
    "    joints = row[\"name\"]\n",
    "    joint_map = [np.argwhere(joints == joint_name)[0][0] for joint_name in joint_order]\n",
    "    row[\"name\"] = joint_order\n",
    "    row[\"position\"] = row[\"position\"][joint_map]\n",
    "    row[\"velocity\"] = row[\"velocity\"][joint_map]\n",
    "    row[\"effort\"] = row[\"effort\"][joint_map]\n",
    "    return row\n",
    "\n",
    "\n",
    "for pose in stationary_data.keys():\n",
    "    for i in range(len(stationary_data[pose])):\n",
    "        df1 = stationary_data[pose][i][\"force_torque\"].drop(columns=columns_to_drop)\n",
    "        df2 = stationary_data[pose][i][\"joint_states\"].drop(columns=columns_to_drop)\n",
    "        df_merged = pd.merge(df1, df2, on=[\"header.stamp\"]).dropna()\n",
    "        stationary_data[pose][i][\"merged\"] = df_merged.apply(reorder_joints, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
